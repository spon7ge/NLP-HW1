{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f8266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e39ec",
   "metadata": {},
   "source": [
    "#### 1. Evaluation Metrics ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input: y_pred, a list of length n with the predicted labels,\n",
    "## y_true, a list of length n with the true labels\n",
    "#                Pred\n",
    "#              |   0   |   1\n",
    "# true    0    |  TN   |  FP\n",
    "#         1    |  FN   |  TP\n",
    "\n",
    "## Calculates the precision of the predicted labels\n",
    "def get_precision(y_pred, y_true):\n",
    "    truePos, falsePos = 0, 0\n",
    "    for i,j in zip(y_pred, y_true):\n",
    "        if i == 1 and j == 1:\n",
    "            truePos += 1\n",
    "        elif i == 1 and j == 0:\n",
    "            falsePos += 1\n",
    "            \n",
    "    if truePos + falsePos == 0: #incase there are no true positives or false positives\n",
    "        return 0\n",
    "    \n",
    "    precision = truePos/(truePos + falsePos)\n",
    "    return precision\n",
    "    \n",
    "## Calculates the recall of the predicted labels\n",
    "def get_recall(y_pred, y_true): #TP/(TP + FN)\n",
    "    truePos, falseNeg = 0, 0\n",
    "    \n",
    "    for i,j in zip(y_pred, y_true):\n",
    "        if i == 1 and j == 1:\n",
    "            truePos += 1\n",
    "        elif i == 0 and j == 1:\n",
    "            falseNeg += 1\n",
    "    recall = truePos/(truePos+falseNeg)\n",
    "    return recall\n",
    "\n",
    "## Calculates the f-score of the predicted labels\n",
    "def get_fscore(y_pred, y_true): #TP/(TP + 1/2(FP + FN))\n",
    "    truePos, falsePos, falseNeg = 0, 0, 0\n",
    "    for i, j in zip(y_pred,y_true):\n",
    "        if i == 1 and j == 1:\n",
    "            truePos += 1\n",
    "        elif i == 1 and j == 0:\n",
    "            falsePos += 1\n",
    "        elif i == 0 and j == 1:\n",
    "            falseNeg += 1\n",
    "    if truePos == 0:\n",
    "        return 0\n",
    "    fscore = truePos/(truePos + 0.5 * (falsePos + falseNeg))\n",
    "    return fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9ff6e",
   "metadata": {},
   "source": [
    "#### 2. Complex Word Identification ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c9b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(data_file):\n",
    "    words = []\n",
    "    labels = []   \n",
    "    with open(data_file, 'rt', encoding=\"utf8\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            if i > 0:\n",
    "                line_split = line[:-1].split(\"\\t\")\n",
    "                words.append(line_split[0].lower())\n",
    "                labels.append(int(line_split[1]))\n",
    "            i += 1\n",
    "    return words, labels\n",
    "\n",
    "## Makes feature matrix for all complex\n",
    "def all_complex_feature(words):\n",
    "    res = []\n",
    "    for word in words:\n",
    "        res.append([1])\n",
    "    return res\n",
    "\n",
    "## Labels every word complex\n",
    "def all_complex(data_file):\n",
    "    ## YOUR CODE HERE...\n",
    "    words, labels = load_file(data_file)\n",
    "    pred = [1] * len(words)\n",
    "\n",
    "    # metrics\n",
    "    precision = get_precision(pred, labels)\n",
    "    recall = get_recall(pred, labels)\n",
    "    fscore = get_fscore(pred, labels)\n",
    "\n",
    "    performance = [precision, recall, fscore]\n",
    "    return performance\n",
    "\n",
    "\n",
    "# ### 2.2: Word length thresholding\n",
    "\n",
    "## Makes feature matrix for word_length_threshold\n",
    "def length_threshold_feature(words, threshold):\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if len(word) >= threshold:\n",
    "            res.append([1])\n",
    "        else:\n",
    "            res.append([0])\n",
    "    return res\n",
    "\n",
    "## Finds the best length threshold by f-score, and uses this threshold to\n",
    "## classify the training and development set\n",
    "def word_length_threshold(training_file, development_file):\n",
    "    ## YOUR CODE HERE\n",
    "    words, labels = load_file(training_file)\n",
    "    best_fscore = 0\n",
    "    best_length = 4\n",
    "    \n",
    "    for i in range(4,11):\n",
    "        res = length_threshold_feature(words,i)\n",
    "        pred = [x[0] for x in res]\n",
    "        \n",
    "        tprecision = get_precision(pred,labels)\n",
    "        trecall = get_recall(pred,labels)\n",
    "        tfscore = get_fscore(pred,labels)\n",
    "        if tfscore > best_fscore:\n",
    "            best_fscore = tfscore\n",
    "            best_length = i\n",
    "            best_precision = tprecision\n",
    "            best_recall = trecall \n",
    "    \n",
    "    dev_words, dev_labels = load_file(development_file)\n",
    "    dev_res = length_threshold_feature(dev_words,best_length)\n",
    "    dev_pred = [x[0] for x in dev_res]\n",
    "    \n",
    "    dprecision = get_precision(dev_pred,dev_labels)\n",
    "    drecall = get_recall(dev_pred,dev_labels)\n",
    "    dfscore = get_fscore(dev_pred,dev_labels)\n",
    "            \n",
    "    training_performance = [best_precision, best_recall, best_fscore]\n",
    "    development_performance = [dprecision, drecall, dfscore]\n",
    "    return training_performance, development_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a0c2ec",
   "metadata": {},
   "source": [
    "### 2.3: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa47755",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trains a Naive Bayes classifier using length and frequency features\n",
    "from syllables import count_syllables\n",
    "\n",
    "vowels = \"aeiou\"\n",
    "wordFreq = {}\n",
    "\n",
    "def getFeatures(word, counts): #helper function to make it easier to get features. also saves me time\n",
    "    wordFeatures = []\n",
    "    count = 0\n",
    "    wordFeatures.append(len(word)) #length of word\n",
    "    wordFeatures.append(count_syllables(word)) #number of syllables\n",
    "    for char in word:\n",
    "        if char in vowels:\n",
    "            count += 1\n",
    "    wordFeatures.append(count) #number of vowels in each word\n",
    "    wordFreq = counts.get(word,0)\n",
    "    wordFeatures.append(wordFreq) #frequency of word\n",
    "    return wordFeatures\n",
    "\n",
    "def naive_bayes(training_file, development_file, counts):\n",
    "    training_words, training_labels = load_file(training_file)\n",
    "    development_words, development_labels = load_file(development_file)\n",
    "    \n",
    "    tFeatures = []\n",
    "    for word in training_words:\n",
    "        tFeatures.append(getFeatures(word, counts))\n",
    "        \n",
    "    probComplex, probSimple = 0, 0\n",
    "    featureProb = {}\n",
    "    for i, features in enumerate(tFeatures):\n",
    "        label = training_labels[i]\n",
    "        # TODO: Count how often each feature value appears with each class\n",
    "        # Update your feature_probs dictionary\n",
    "    \n",
    "    devPred = []\n",
    "    for word in development_words:\n",
    "        wordFeatures = getFeatures(word, counts)\n",
    "        scoreComplex = probComplex\n",
    "        scoreSimple = probSimple\n",
    "        for featureValue in wordFeatures:\n",
    "        # score_complex *= P(feature_value | complex)\n",
    "        # score_simple *= P(feature_value | simple)\n",
    "            pass\n",
    "        if scoreComplex > scoreSimple:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = 0\n",
    "        devPred.append(prediction)\n",
    "        \n",
    "    trainingPred = []\n",
    "    tprecision = get_precision(trainingPred, training_labels)\n",
    "    trecall = get_recall(trainingPred, training_labels)\n",
    "    tfscore = get_fscore(trainingPred, training_labels)\n",
    "    \n",
    "    dprecision = get_precision(devPred, development_labels)\n",
    "    drecall = get_recall(devPred, development_labels)\n",
    "    dfscore = get_fscore(devPred, development_labels)\n",
    "    \n",
    "    training_performance = (tprecision, trecall, tfscore)\n",
    "    development_performance = (dprecision, drecall, dfscore)\n",
    "    return development_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba52c36",
   "metadata": {},
   "source": [
    "### 2.4: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(training_file, development_file, counts):\n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    training_performance = (tprecision, trecall, tfscore)\n",
    "    development_performance = (dprecision, drecall, dfscore)\n",
    "    return development_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d3c348",
   "metadata": {},
   "source": [
    "### 2.7: Build your own classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0b0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad0c54d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    training_file = \"data/complex_words_training.txt\"\n",
    "    development_file = \"data/complex_words_development.txt\"\n",
    "    test_file = \"data/complex_words_test_unlabeled.txt\"\n",
    "\n",
    "    train_data = load_file(training_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
